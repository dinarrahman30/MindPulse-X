{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cac1f779",
   "metadata": {},
   "source": [
    "# Klasifikasi Teks Untuk Mendeteksi Depresi dan Kecemasan pada Pengguna Twitter (X) dengan Model Klasik"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a2cb51c",
   "metadata": {},
   "source": [
    "#### About Dataset\n",
    "This comprehensive dataset is a meticulously curated collection of mental health statuses tagged from various statements. The dataset amalgamates raw data from multiple sources, cleaned and compiled to create a robust resource for developing chatbots and performing sentiment analysis.\n",
    "\n",
    "**Data Source**:\n",
    "The dataset integrates information from the following Kaggle datasets:\n",
    "\n",
    "- 3k Conversations Dataset for Chatbot\n",
    "- Depression Reddit Cleaned\n",
    "- Human Stress Prediction\n",
    "- Predicting Anxiety in Mental Health Data\n",
    "- Mental Health Dataset Bipolar\n",
    "- Reddit Mental Health Data\n",
    "- Students Anxiety and Depression \n",
    "- Suicidal Mental Health Dataset\n",
    "- Suicidal Tweet Detection Dataset\n",
    "\n",
    "**Data Overview**:\n",
    "The dataset consists of statements tagged with one of the following seven mental health statuses:\n",
    "\n",
    "- Normal\n",
    "- Depression\n",
    "- Suicidal\n",
    "- Anxiety\n",
    "- Stress\n",
    "- Bi-Polar\n",
    "- Personality Disorder\n",
    "\n",
    "**Data Collection**:\n",
    "The data is sourced from diverse platforms including social media posts, Reddit posts, Twitter posts, and more. Each entry is tagged with a specific mental health status, making it an invaluable asset for:\n",
    "\n",
    "- Developing intelligent mental health chatbots.\n",
    "- Performing in-depth sentiment analysis.\n",
    "- Research and studies related to mental health trends.\n",
    "\n",
    "**Features**:\n",
    "\n",
    "- unique_id: A unique identifier for each entry.\n",
    "- Statement: The textual data or post.\n",
    "- Mental Health Status: The tagged mental health status of the statement.\n",
    "\n",
    "**Usage**:\n",
    "This dataset is ideal for training machine learning models aimed at understanding and predicting mental health conditions based on textual data. It can be used in various applications such as:\n",
    "\n",
    "- ~~Chatbot development for mental health support.~~\n",
    "- Sentiment analysis to gauge mental health trends.\n",
    "- Academic research on mental health patterns.\n",
    "\n",
    "**Acknowledgments**:\n",
    "This dataset was created by aggregating and cleaning data from various publicly available datasets on Kaggle. Special thanks to the original dataset creators for their contributions.\n",
    "\n",
    "Source: [Kaggle]('https://www.kaggle.com/datasets/suchintikasarkar/sentiment-analysis-for-mental-health')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdcc6629",
   "metadata": {},
   "source": [
    "## Data Collection"
   ]
  },
  {
   "cell_type": "code",
   "id": "85d7ed2d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-05T12:16:46.419994Z",
     "start_time": "2025-11-05T12:16:35.222554Z"
    }
   },
   "source": [
    "import pandas as pd"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "c20731ee",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-05T12:16:47.235258Z",
     "start_time": "2025-11-05T12:16:46.537204Z"
    }
   },
   "source": [
    "df = pd.read_csv('D:\\Portfolio project\\Mental Health Sentiment Analysis in Twitter\\Data\\Cleaned Combined Data.csv')\n",
    "df.head()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "    status                                 cleaned_statements\n",
       "0  Anxiety                                         oh my gosh\n",
       "1  Anxiety  trouble sleeping, confused mind, restless hear...\n",
       "2  Anxiety  All wrong, back off dear, forward doubt. Stay ...\n",
       "3  Anxiety  I've shifted my focus to something else but I'...\n",
       "4  Anxiety  I'm restless and restless, it's been a month n..."
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>status</th>\n",
       "      <th>cleaned_statements</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Anxiety</td>\n",
       "      <td>oh my gosh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Anxiety</td>\n",
       "      <td>trouble sleeping, confused mind, restless hear...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Anxiety</td>\n",
       "      <td>All wrong, back off dear, forward doubt. Stay ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Anxiety</td>\n",
       "      <td>I've shifted my focus to something else but I'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Anxiety</td>\n",
       "      <td>I'm restless and restless, it's been a month n...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "b2d2a6e2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-05T12:16:47.376008Z",
     "start_time": "2025-11-05T12:16:47.364481Z"
    }
   },
   "source": [
    "df.shape"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(52681, 2)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "id": "b500f2a0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-05T12:16:55.530375Z",
     "start_time": "2025-11-05T12:16:55.496158Z"
    }
   },
   "source": [
    "df.value_counts('status')"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "status\n",
       "Normal                  16343\n",
       "Depression              15404\n",
       "Suicidal                10652\n",
       "Anxiety                  3841\n",
       "Bipolar                  2777\n",
       "Stress                   2587\n",
       "Personality disorder     1077\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "id": "6bf37558",
   "metadata": {},
   "source": [
    "### Cek Data"
   ]
  },
  {
   "cell_type": "code",
   "id": "2cf86403",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-05T12:16:56.578111Z",
     "start_time": "2025-11-05T12:16:56.288906Z"
    }
   },
   "source": [
    "df.duplicated().sum()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(1606)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "id": "4d7f9d1a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-05T12:16:57.326669Z",
     "start_time": "2025-11-05T12:16:57.079433Z"
    }
   },
   "source": [
    "df.drop_duplicates()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "        status                                 cleaned_statements\n",
       "0      Anxiety                                         oh my gosh\n",
       "1      Anxiety  trouble sleeping, confused mind, restless hear...\n",
       "2      Anxiety  All wrong, back off dear, forward doubt. Stay ...\n",
       "3      Anxiety  I've shifted my focus to something else but I'...\n",
       "4      Anxiety  I'm restless and restless, it's been a month n...\n",
       "...        ...                                                ...\n",
       "52478  Anxiety  Anxiety cause faintness when standing up ? As ...\n",
       "52479  Anxiety  anxiety heart symptom does anyone else have th...\n",
       "52480  Anxiety  Travel Anxiety Hi all! Long time anxiety suffe...\n",
       "52481  Anxiety  fomo from things i’m not involved in does anyo...\n",
       "52482  Anxiety  Getting through the day How do you get anythin...\n",
       "\n",
       "[51075 rows x 2 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>status</th>\n",
       "      <th>cleaned_statements</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Anxiety</td>\n",
       "      <td>oh my gosh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Anxiety</td>\n",
       "      <td>trouble sleeping, confused mind, restless hear...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Anxiety</td>\n",
       "      <td>All wrong, back off dear, forward doubt. Stay ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Anxiety</td>\n",
       "      <td>I've shifted my focus to something else but I'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Anxiety</td>\n",
       "      <td>I'm restless and restless, it's been a month n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52478</th>\n",
       "      <td>Anxiety</td>\n",
       "      <td>Anxiety cause faintness when standing up ? As ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52479</th>\n",
       "      <td>Anxiety</td>\n",
       "      <td>anxiety heart symptom does anyone else have th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52480</th>\n",
       "      <td>Anxiety</td>\n",
       "      <td>Travel Anxiety Hi all! Long time anxiety suffe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52481</th>\n",
       "      <td>Anxiety</td>\n",
       "      <td>fomo from things i’m not involved in does anyo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52482</th>\n",
       "      <td>Anxiety</td>\n",
       "      <td>Getting through the day How do you get anythin...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>51075 rows × 2 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "id": "60cbb8c6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-05T12:16:57.906060Z",
     "start_time": "2025-11-05T12:16:57.881500Z"
    }
   },
   "source": [
    "df.isnull().sum()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "status                0\n",
       "cleaned_statements    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "id": "30e0cb2e",
   "metadata": {},
   "source": [
    "### Cleaning Data"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-05T12:17:01.268803Z",
     "start_time": "2025-11-05T12:17:01.253989Z"
    }
   },
   "source": [
    "df.shape"
   ],
   "id": "f6b4116ec06b14c2",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(52681, 2)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "id": "a4255fb2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-05T12:17:02.288633Z",
     "start_time": "2025-11-05T12:17:02.005800Z"
    }
   },
   "source": [
    "df.describe()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "        status cleaned_statements\n",
       "count    52681              52681\n",
       "unique       7              51053\n",
       "top     Normal  what do you mean?\n",
       "freq     16343                 22"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>status</th>\n",
       "      <th>cleaned_statements</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>52681</td>\n",
       "      <td>52681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>7</td>\n",
       "      <td>51053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Normal</td>\n",
       "      <td>what do you mean?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>16343</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "id": "e88258d3",
   "metadata": {},
   "source": [
    "### Exploratory Data Analysis\n",
    "Membantu memahami dataset sebelum training model, mengidentifikasi pola, masalah, dan memandu preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "id": "885c0764",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-05T12:17:05.254260Z",
     "start_time": "2025-11-05T12:17:02.536189Z"
    }
   },
   "source": [
    "import matplotlib.pyplot as plt"
   ],
   "outputs": [],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "id": "df0b428b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-05T12:17:06.093574Z",
     "start_time": "2025-11-05T12:17:06.075465Z"
    }
   },
   "source": [
    "df.value_counts('status')"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "status\n",
       "Normal                  16343\n",
       "Depression              15404\n",
       "Suicidal                10652\n",
       "Anxiety                  3841\n",
       "Bipolar                  2777\n",
       "Stress                   2587\n",
       "Personality disorder     1077\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 11
  },
  {
   "cell_type": "markdown",
   "id": "bfa9f5e2",
   "metadata": {},
   "source": [
    "### Dengan Model Klasik (TF-IDF + Desicion Tree/Random Forest/Naive Bayes/SVM/Logistic Regression)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9e5f02f",
   "metadata": {},
   "source": [
    "### Text Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "id": "f951cf74",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-05T12:17:06.591177Z",
     "start_time": "2025-11-05T12:17:06.574891Z"
    }
   },
   "source": [
    "df_classic = df.copy()"
   ],
   "outputs": [],
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "id": "62298890",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-05T12:17:21.583846Z",
     "start_time": "2025-11-05T12:17:06.883197Z"
    }
   },
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\dinar\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\dinar\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "id": "fc77958a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-05T12:18:49.695603Z",
     "start_time": "2025-11-05T12:17:22.008768Z"
    }
   },
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "stemmer = WordNetLemmatizer()\n",
    "def preprocess_text(text):\n",
    "    text = text.lower() # Lowercasing\n",
    "    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE) # Remove URLs\n",
    "    text = re.sub(r'\\@w+|\\#','', text) # Remove mentions and hashtags\n",
    "    text = re.sub(r'[^a-zA-Z]', ' ', text) # Remove special characters and numbers\n",
    "    tokens = text.split() # Tokenization\n",
    "    tokens = [word for word in tokens if word not in stop_words] # Remove stopwords\n",
    "    tokens = [stemmer.lemmatize(word) for word in tokens] # Lemmatization\n",
    "    return ' '.join(tokens) \n",
    "df_classic['cleaned_statements'] = df_classic['cleaned_statements'].apply(preprocess_text) \n",
    "df_classic[['cleaned_statements']].head() "
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                  cleaned_statements\n",
       "0                                            oh gosh\n",
       "1  trouble sleeping confused mind restless heart ...\n",
       "2  wrong back dear forward doubt stay restless re...\n",
       "3         shifted focus something else still worried\n",
       "4                   restless restless month boy mean"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cleaned_statements</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>oh gosh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>trouble sleeping confused mind restless heart ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>wrong back dear forward doubt stay restless re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>shifted focus something else still worried</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>restless restless month boy mean</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "id": "16ca42c8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-05T12:18:49.958303Z",
     "start_time": "2025-11-05T12:18:49.939118Z"
    }
   },
   "source": [
    "df_classic.head()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "    status                                 cleaned_statements\n",
       "0  Anxiety                                            oh gosh\n",
       "1  Anxiety  trouble sleeping confused mind restless heart ...\n",
       "2  Anxiety  wrong back dear forward doubt stay restless re...\n",
       "3  Anxiety         shifted focus something else still worried\n",
       "4  Anxiety                   restless restless month boy mean"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>status</th>\n",
       "      <th>cleaned_statements</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Anxiety</td>\n",
       "      <td>oh gosh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Anxiety</td>\n",
       "      <td>trouble sleeping confused mind restless heart ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Anxiety</td>\n",
       "      <td>wrong back dear forward doubt stay restless re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Anxiety</td>\n",
       "      <td>shifted focus something else still worried</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Anxiety</td>\n",
       "      <td>restless restless month boy mean</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 15
  },
  {
   "cell_type": "markdown",
   "id": "e544bdc0",
   "metadata": {},
   "source": [
    "#### Feature extration with TFIDFVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afe95892",
   "metadata": {},
   "source": [
    "**Untuk case ini, feature engineering tidak diperlukan.**"
   ]
  },
  {
   "cell_type": "code",
   "id": "f1ae51cf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-05T12:18:50.223936Z",
     "start_time": "2025-11-05T12:18:50.214146Z"
    }
   },
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "#from sklearn.pipeline import FeatureUnion, Pipeline\n",
    "#from sklearn.svm import LinearSVC\n",
    "#from sklearn.preprocessing import FucntionTransformer\n",
    "\n",
    "def extract_features(df_classic):\n",
    "    # Initialize TF-IDF vectorizer\n",
    "    tfidf = TfidfVectorizer(\n",
    "        max_features=5000,  # Limit features to top 5000 terms\n",
    "        min_df=5,          # Ignore terms that appear in less than 5 documents\n",
    "        max_df=0.95,       # Ignore terms that appear in more than 95% of documents\n",
    "        stop_words='english',\n",
    "        ngram_range=(1, 2) # Include both unigrams and bigrams\n",
    "    )\n",
    "    \n",
    "    # Fit and transform the text data\n",
    "    features = tfidf.fit_transform(df_classic)\n",
    "    \n",
    "    # Convert to DataFrame for better visualization\n",
    "    feature_names = tfidf.get_feature_names_out()\n",
    "    feature_matrix = pd.DataFrame(\n",
    "        features.toarray(),\n",
    "        columns=feature_names\n",
    "    )\n",
    "    \n",
    "    return feature_matrix, tfidf"
   ],
   "outputs": [],
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "id": "f75cfa32",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-05T12:18:58.987102Z",
     "start_time": "2025-11-05T12:18:50.281011Z"
    }
   },
   "source": [
    "# Extract features\n",
    "feature_matrix, tfidf = extract_features(df_classic['cleaned_statements'])\n",
    "\n",
    "# Now feature_matrix can be used for machine learning models\n",
    "print(f\"Shape of feature matrix: {feature_matrix.shape}\")\n",
    "print(f\"Number of unique terms: {len(tfidf.get_feature_names_out())}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of feature matrix: (52681, 5000)\n",
      "Number of unique terms: 5000\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "id": "e4424a31",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-05T12:18:59.930701Z",
     "start_time": "2025-11-05T12:18:59.669884Z"
    }
   },
   "source": [
    "# Split the dataset into training and testing sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df_classic['cleaned_statements']\n",
    "y = df_classic['status']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ],
   "outputs": [],
   "execution_count": 18
  },
  {
   "cell_type": "markdown",
   "id": "8b5dfc37",
   "metadata": {},
   "source": [
    "**Memakai model Logistic Regression/Naive Bayes/Random Forest**"
   ]
  },
  {
   "cell_type": "code",
   "id": "a9fc8c10",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-05T12:21:45.959703Z",
     "start_time": "2025-11-05T12:19:00.348027Z"
    }
   },
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, f1_score\n",
    "from sklearn.pipeline import make_pipeline\n",
    "import joblib\n",
    "import os\n",
    "\n",
    "models = (\n",
    "    RandomForestClassifier(),\n",
    "    MultinomialNB(),\n",
    "    LogisticRegression(max_iter=200),\n",
    ")\n",
    "models_names = ['Random Forest', 'Multinomial Naive Bayes', 'Logistic Regression']\n",
    "\n",
    "best_score = -1.0\n",
    "best_pipeline = None\n",
    "best_name = None\n",
    "\n",
    "for model, name in zip(models, models_names):\n",
    "    pipeline = make_pipeline(tfidf, model)   # tfidf, X_train, y_train sudah didefinisikan sebelumnya\n",
    "\n",
    "    # Train the model\n",
    "    pipeline.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions\n",
    "    y_pred = pipeline.predict(X_test)\n",
    "\n",
    "    # Evaluate the model\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "    print(f\"Model: {name}\")\n",
    "    print(\"Accuracy:\", acc)\n",
    "    print(\"F1 Score:\", f1)\n",
    "    print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "    print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "    # cek apakah model ini yang terbaik sejauh ini (berdasarkan F1)\n",
    "    if f1 > best_score:\n",
    "        best_score = f1\n",
    "        best_pipeline = pipeline\n",
    "        best_name = name\n",
    "\n",
    "print(f\"Model terbaik: {best_name} dengan F1 Score = {best_score:.4f}\")\n",
    "\n",
    "# ====== SIMPAN MODEL TERBAIK ======\n",
    "os.makedirs(\"../saved_models\", exist_ok=True)\n",
    "\n",
    "# bikin nama file dari nama model\n",
    "filename = best_name.lower().replace(\" \", \"_\") + \"_pipeline.joblib\"\n",
    "filepath = os.path.join(\"../saved_models\", filename)\n",
    "\n",
    "joblib.dump(best_pipeline, filepath)\n",
    "print(f\"Model terbaik disimpan di: {filepath}\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Random Forest\n",
      "Accuracy: 0.7120622568093385\n",
      "F1 Score: 0.7007663991753732\n",
      "Classification Report:\n",
      "                       precision    recall  f1-score   support\n",
      "\n",
      "             Anxiety       0.84      0.64      0.73       755\n",
      "             Bipolar       0.94      0.51      0.66       527\n",
      "          Depression       0.56      0.78      0.66      3016\n",
      "              Normal       0.84      0.94      0.89      3308\n",
      "Personality disorder       0.99      0.38      0.55       237\n",
      "              Stress       0.94      0.27      0.42       536\n",
      "            Suicidal       0.68      0.48      0.56      2158\n",
      "\n",
      "            accuracy                           0.71     10537\n",
      "           macro avg       0.83      0.57      0.64     10537\n",
      "        weighted avg       0.74      0.71      0.70     10537\n",
      "\n",
      "Confusion Matrix:\n",
      " [[ 482    0  185   66    0    5   17]\n",
      " [   4  271  215   20    0    0   17]\n",
      " [  45    8 2363  206    0    2  392]\n",
      " [  15    2  145 3107    0    1   38]\n",
      " [   3    0  125   13   90    1    5]\n",
      " [  23    1  262   73    1  145   31]\n",
      " [   1    7  889  215    0    1 1045]]\n",
      "--------------------------------------------------\n",
      "Model: Multinomial Naive Bayes\n",
      "Accuracy: 0.653886305400019\n",
      "F1 Score: 0.6409253080974745\n",
      "Classification Report:\n",
      "                       precision    recall  f1-score   support\n",
      "\n",
      "             Anxiety       0.79      0.66      0.72       755\n",
      "             Bipolar       0.84      0.44      0.57       527\n",
      "          Depression       0.50      0.76      0.60      3016\n",
      "              Normal       0.82      0.81      0.81      3308\n",
      "Personality disorder       0.89      0.10      0.18       237\n",
      "              Stress       0.87      0.11      0.20       536\n",
      "            Suicidal       0.66      0.52      0.58      2158\n",
      "\n",
      "            accuracy                           0.65     10537\n",
      "           macro avg       0.77      0.48      0.52     10537\n",
      "        weighted avg       0.70      0.65      0.64     10537\n",
      "\n",
      "Confusion Matrix:\n",
      " [[ 495    7  162   87    0    2    2]\n",
      " [   5  230  241   41    0    0   10]\n",
      " [  56   25 2287  194    0    1  453]\n",
      " [  11    5  547 2671    0    5   69]\n",
      " [   1    3  178   23   24    0    8]\n",
      " [  51    1  288  107    3   59   27]\n",
      " [  10    4  871  148    0    1 1124]]\n",
      "--------------------------------------------------\n",
      "Model: Logistic Regression\n",
      "Accuracy: 0.7386352851855367\n",
      "F1 Score: 0.7323980116503\n",
      "Classification Report:\n",
      "                       precision    recall  f1-score   support\n",
      "\n",
      "             Anxiety       0.82      0.75      0.78       755\n",
      "             Bipolar       0.87      0.61      0.72       527\n",
      "          Depression       0.64      0.72      0.68      3016\n",
      "              Normal       0.84      0.94      0.89      3308\n",
      "Personality disorder       0.90      0.37      0.52       237\n",
      "              Stress       0.71      0.40      0.51       536\n",
      "            Suicidal       0.66      0.61      0.63      2158\n",
      "\n",
      "            accuracy                           0.74     10537\n",
      "           macro avg       0.78      0.63      0.68     10537\n",
      "        weighted avg       0.74      0.74      0.73     10537\n",
      "\n",
      "Confusion Matrix:\n",
      " [[ 564    6   88   69    2   20    6]\n",
      " [   7  324  126   31    3    7   29]\n",
      " [  63   23 2175  209    3   19  524]\n",
      " [  11    5  100 3094    1   28   69]\n",
      " [   4    2   96   23   87    7   18]\n",
      " [  36    4  151   81    1  216   47]\n",
      " [   2    9  638  177    0    9 1323]]\n",
      "--------------------------------------------------\n",
      "Model terbaik: Logistic Regression dengan F1 Score = 0.7324\n",
      "Model terbaik disimpan di: saved_models\\logistic_regression_pipeline.joblib\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "id": "7c0fdd6b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-05T12:21:46.204318Z",
     "start_time": "2025-11-05T12:21:46.125603Z"
    }
   },
   "source": [
    "pipeline = joblib.load(\"../saved_models\\logistic_regression_pipeline.joblib\")\n",
    "\n",
    "text_baru = [\"I feel very anxious and lonely\"]\n",
    "\n",
    "pred_label = pipeline.predict(text_baru)[0]\n",
    "\n",
    "if hasattr(pipeline, \"predict_proba\"):\n",
    "    probs = pipeline.predict_proba(text_baru)[0]\n",
    "    classes = pipeline.classes_\n",
    "    print(\"Prediksi:\", pred_label)\n",
    "    for cls, p in zip(classes, probs):\n",
    "        print(f\"{cls}: {p:.3f}\")\n",
    "else:\n",
    "    print(\"Prediksi:\", pred_label)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediksi: Anxiety\n",
      "Anxiety: 0.687\n",
      "Bipolar: 0.012\n",
      "Depression: 0.173\n",
      "Normal: 0.040\n",
      "Personality disorder: 0.011\n",
      "Stress: 0.028\n",
      "Suicidal: 0.049\n"
     ]
    }
   ],
   "execution_count": 20
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
